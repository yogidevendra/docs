<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>dtIngest - DataTorrent Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "dtIngest";
    var mkdocs_page_input_path = "dtingest.md";
    var mkdocs_page_url = "/dtingest/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-44586211-2', 'docs.datatorrent.com');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> DataTorrent Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">DataTorrent RTS</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Demos</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../demos/">Running Apps</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../sandbox/">Sandbox</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Cloud Integration</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../aws_emr_manual/">AWS</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Development</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../create/">Creating Applications</a>
                </li>
                <li class="">
                    
    <a class="" href="../beginner/">Beginner's Guide</a>
                </li>
                <li class="">
                    
    <a class="" href="../demo_videos/">Videos</a>
                </li>
                <li class="">
                    
    <span class="caption-text">Tutorials</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <span class="caption-text">Top N Words</span>
    <ul class="subnav">
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords/">Introduction</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c1/">Development Environment</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c2/">Building in Java</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c3/">Building with dtAssemble</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c4/">Monitoring with dtManage</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c5/">Visualizing with dtDashboard</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c7/">Advanced Features</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/topnwords-c6/">Appendix</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3">
                    
    <span class="caption-text">Sales Dimensions</span>
    <ul class="subnav">
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/salesdimensions/">Building in Java</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/salesdimensions-c2/">Building with dtAssemble</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/salesdimensions-c3/">Visualizing with dtDashboard</a>
                </li>
                <li class="toctree-l4">
                    
    <a class="" href="../tutorials/salesdimensions-c4/">Monitoring with dtManage</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../apex_development_setup/">Apex Development Setup</a>
                </li>
                <li class="">
                    
    <a class="" href="../configure_IDE/">Generate New Project in IDE</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_development/">Applications</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_packages/">Application Packages</a>
                </li>
                <li class="">
                    
    <a class="" href="../configuration_packages/">Configuration Packages</a>
                </li>
                <li class="">
                    
    <a class="" href="../operator_development/">Operators</a>
                </li>
                <li class="">
                    
    <span class="caption-text">Library Operators</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../library_operators/">List of Operators</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/block_reader/">Block Reader</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/deduper/">Deduper</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/dimensions_computation/">Dimension Computation</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/file_output/">File Output</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/file_splitter/">File Splitter</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/hdht/">HDHT</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/kafkaInputOperator/">Kafka Input</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/snapshot_server/">Snapshot Server</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../app_data_framework/">App Data Framework</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_api/">REST API</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">App Templates</span>
    <ul class="subnav">
                <li class="">
                    
    <span class="caption-text">0.10.0</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/common/import-launch/">Import and Launch App-template</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/common/customize/">Customizing an app-template</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/database-to-database-sync/">Database-to-database-sync</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-line-copy/">HDFS-line-copy</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-part-file-copy/">HDFS-part-file-copy</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-to-hdfs-filter-transform/">HDFS-to-HDFS-filter-transform</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-cassandra-filter-transform/">Kafka-to-Cassandra-Filter-Transform</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-database-sync/">Kafka-to-Database-sync</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-hdfs-filter-transform/">Kafka-to-HDFS-Filter-Transform</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-kafka-filter-transform/">Kafka-to-Kafka-Filter-Transform</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kinesis-to-redshift/">Kinesis-to-Redshift</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/kinesis-to-s3/">Kinesis-to-S3</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/s3-to-hdfs-sync/">S3-to-HDFS-sync</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../app-templates/0.10.0/s3-to-redshift/">S3-to-HDFS-Filter-Transform</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/database-to-hdfs/">Database dump to HDFS App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/database-to-database-sync/">Database to Database Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-sync/">HDFS Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-line-copy/">HDFS to HDFS Line Copy App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-to-kafka-sync/">HDFS to Kafka Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-database-sync/">Kafka to Database Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-hdfs-filter/">Kafka to HDFS Filter App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-hdfs-sync/">Kafka to HDFS Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kinesis-to-s3/">Kinesis to S3 App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/s3-to-hdfs-sync/">S3 to HDFS Sync App</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Applications</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../app_data_tracker/">App Data Tracker</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">dtIngest</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#dtingest-tutorial">dtIngest Tutorial</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#pre-requisites">Pre-requisites</a></li>
        
            <li><a class="toctree-l4" href="#launching-dtingest">Launching dtIngest</a></li>
        
            <li><a class="toctree-l4" href="#configuring-dtingest-instance-properties">Configuring dtIngest Instance Properties</a></li>
        
            <li><a class="toctree-l4" href="#configuring-input-source">Configuring Input Source</a></li>
        
            <li><a class="toctree-l4" href="#configuring-output-destination">Configuring Output Destination</a></li>
        
            <li><a class="toctree-l4" href="#configuring-processing-steps">Configuring Processing Steps</a></li>
        
        </ul>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Platform</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../rts/">RTS</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_configurations/">Application Configurations</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtmanage/">dtManage</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtassemble/">dtAssemble</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtdashboard/">dtDashboard</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway/">dtGateway</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_systemalerts/">Alerts</a>
                </li>
                <li class="">
                    
    <a class="" href="../apex/">Apache Apex</a>
                </li>
                <li class="">
                    
    <a class="" href="../apex_malhar/">Apache Apex-Malhar</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Deployment and Operations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../installation/">Installation</a>
                </li>
                <li class="">
                    
    <a class="" href="../configuration/">Configuration</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_security/">Security</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_systemalerts/">System Alerts</a>
                </li>
                <li class="">
                    
    <a class="" href="../apexcli/">Apex CLI</a>
                </li>
                <li class="">
                    
    <a class="" href="../troubleshooting/">Troubleshooting</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../release_notes/">Release Notes</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../glossary/">Glossary</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../additional_docs/">Resources</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">DataTorrent Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Applications &raquo;</li>
        
      
    
    <li>dtIngest</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="dtingest-tutorial">dtIngest Tutorial</h1>
<p>"dtIngest" is a DataTorrent application that ingest data from various
sources and egress the processed data to various sinks. The data movement
happens at scale and in parallel. To know more about dtIngest please
refer the <a href="https://www.datatorrent.com/dtingest-unified-streaming-batch-data-ingestion-hadoop/">dtIngest
blog</a>.</p>
<p>This tutorial refers to dtIngest version 1.0.0</p>
<h2 id="pre-requisites">Pre-requisites</h2>
<ul>
<li>
<p>Datatorrent RTS on a Hadoop cluster. Please
    refer to <a href="http://docs.datatorrent.com/installation/">Installation
    guide</a> for
    details.</p>
</li>
<li>
<p>Source and destination file systems must be accessible from all
    DataTorrent RTS nodes. It can be any of HDFS,
    NFS, S3, FTP. For sandbox image or single node hadoop cluster you can also use local
    files as source. But, for multi-node cluster local files cannot be used as source.</p>
</li>
<li>
<p>If source or destination file system is NFS; then NFS
    should be mounted on all the nodes within the Hadoop cluster at a
    common mount point and should have read/write permission to the user
    running dtIngest application.</p>
</li>
</ul>
<h2 id="launching-dtingest">Launching dtIngest</h2>
<p>dtIngest application can be configured and launched from <a href="http://docs.datatorrent.com/dtmanage/">Datatorrent
Management
Console</a>.</p>
<ol>
<li>
<p>Navigate to 'Develop' tab.
    <img alt="Screenshot from 2015-09-24 16:33:45.png" src="../images/dtingest/image45.png" /></p>
</li>
<li>
<p>The dtIngest application package is already uploaded and available
    to use under 'Application Packages' section. </p>
</li>
<li>
<p>Select 'Ingestion Application' from the list of App packages. And click
    on ‘launch application’ button.
    <img alt="Screenshot from 2015-09-24 16:37:23.png" src="../images/dtingest/image13.png" /></p>
</li>
<li>
<p>Configuration page for dtingest is displayed after the 'launch'.
    Enter the configuration values and click
    'Launch' to ingest your data.</p>
</li>
</ol>
<h2 id="configuring-dtingest-instance-properties">Configuring dtIngest Instance Properties</h2>
<ol>
<li>
<p>In the 'Name this application' textbox; name the application instance. For example, 'Ingestion
    test'
    <img alt="Screenshot from 2015-10-15 13:58:10.png" src="../images/dtingest/image33.png" /></p>
</li>
<li>
<p>Leave 'Specify a queue' unchecked to use default queue.</p>
<p>If you want to specify a queue to launch this application, check 'Specify a queue' checkbox and select queue from the
dropdown. For more information, go to <a href="https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Hadoop Capacity Scheduler Docs</a>
<img alt="Screenshot from 2015-10-15 15:20:19.png" src="../images/dtingest/image10.png" /></p>
</li>
<li>
<p>Under 'Use config a file' option, check the box to use existing configuration file. Select file from drop down to load the configuration file.
    <img alt="Screenshot from 2015-10-15 16:10:03.png" src="../images/dtingest/image32.png" /></p>
<p>Once it is loaded, you can modify the values. You can save the new configuration as a new file or overwrite the existing one. </p>
<p>Leave 'Use a config file' unchecked to create a new one. </p>
</li>
<li>
<p>Configure input source, refer to <a href="#configuring-input-source">Configuring input
    source</a> section for details.</p>
</li>
<li>
<p>Configure output destination, refer to <a href="#configuring-output-destination">Configuring output
    destination</a> section for details.</p>
</li>
<li>
<p>Configure processing steps, refer to <a href="#configuring-processing-steps">Configuring processing
    steps</a> section for details.</p>
</li>
<li>
<p>Under 'Save Configuration file' give name for configuration; if
    you wish to save this combination of values for future use.
    You may keep this blank if you do not want to save this for future use. </p>
</li>
</ol>
<h2 id="configuring-input-source">Configuring Input Source</h2>
<h3 id="configuring-hdfs-input">Configuring HDFS input</h3>
<ol>
<li>
<p>For 'Input data source' field; select 'HDFS' option from the
    drop-down.<br />
<img alt="" src="../images/dtingest/image26.png" /></p>
</li>
<li>
<p>Under 'Source directories'; specify complete URL for the file path
    to be ingested.<br />
    For example, if the namenode is 'namenode1.cluster.company.org' and
    port is '8020' and file path is ''/user/john/data' then complete URL in
    this case will be
    <code>hdfs://namenode1.cluster.company.org:8020/user/john/data</code>.<br />
    Where,</p>
<ul>
<li><code>hdfs://</code> indicates HDFS protocol</li>
<li><code>namenode1.cluster.company.org</code> indicates fully qualified domain
   name for the namenode of source HDFS.</li>
<li><code>8020</code> indicates port number for HDFS namenode service</li>
<li><code>/user/john/data</code> indicates full path for destination directory  </li>
</ul>
<p><img alt="" src="../images/dtingest/image14.png" /></p>
<p>If there are more than one directories/file to be ingested, click on
'Add directory' button and specify complete URL file path to be
ingested.</p>
</li>
<li>
<p>In the 'Filtering criteria' field, specify regular expression for
    files to be copied.  For regular expression syntax, please refer to
    <a href="http://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html">Java regular expression  documentation</a>.
     For example, if only <code>.log</code> files need to be ingested, then use <code>.*\.log</code> as regular expression.  </p>
<p><img alt="Screenshot from 2015-09-24 19:36:18.png" src="../images/dtingest/image02.png" /></p>
<p>Where,
-   <code>.*</code> indicates any character zero or more times
-   <code>\.</code> indicates dot escaped with backslash
-   <code>log</code> indicates desired extension which is 'log'</p>
<p>In this case, dtingest ingests only '.log' files from the source
directories.</p>
</li>
<li>
<p>Under 'Runs' field, select 'Single run' if you want
    application to shutdown after completing files ingestion.</p>
<p>Select 'Polling' if you expect application to periodically poll the
directory/file for changes. File change is based on timestamp difference. Entire file will be ingested again in case of
any change.</p>
<p>If 'Polling' mode is selected, then 'Polling interval' should be specified.
This is the time interval between subsequent scans for detecting
new/modified files.  </p>
<p><img alt="Screenshot from 2015-09-24 20:03:57.png" src="../images/dtingest/image17.png" /></p>
</li>
</ol>
<h3 id="configuring-nfs-input">Configuring NFS input</h3>
<ol>
<li>
<p>For 'Input data source' field; select 'File/NFS' option from the
    drop-down. <img alt="Screenshot from 2015-09-24 15:23:24.png" src="../images/dtingest/image31.png" /></p>
</li>
<li>
<p>Under 'Source directories'; specify complete URL file path.</p>
<p>For example, if the NFS mount is located at '/disk5/nfsmount' and
'path/to/data/directory' is the directory under this mount which needs
to be ingested; then complete URL in this case will be <code>file:///disk5/nfsmount/path/to/data/directory</code>.
Where,
-   <code>file://</code> indicates that it is some file system mounted on the node.
-   <code>/disk5/nfsmount/</code> indicates the mount point. Note that, this has
to be uniform across all the nodes in the cluster
-   <code>path/to/data/directory</code> is the directory to be ingested</p>
<p><img alt="Screenshot from 2015-09-24 16:41:29.png" src="../images/dtingest/image37.png" /></p>
<p>Note that, for the above example, there should be <code>///</code> (triple slash)
after <code>file:</code>.</p>
</li>
<li>
<p>If there are more than one directories to be ingested, click on
    'Add directory' button and specify complete URL file
    path.</p>
</li>
<li>
<p>If there are specific files, as opposed to a directory,specify complete
    URL file path.</p>
<p>For example,  if some other NFS mount is located at '/disk6/nfsmount2' and 'path/to/file/to/copy/datafile.txt' is a file under this mount which needs
to be ingested; then complete URL in this case will be <code>file:///disk6/nfsmount2/path/to/file/to/copy/datafile.txt</code>.</p>
<p><img alt="Screenshot from 2015-09-24 17:36:06.png" src="../images/dtingest/image39.png" /></p>
</li>
<li>
<p>In the 'Filtering criteria' field, specify regular expression for
    files to be copied.
    For example, if only <code>.log</code> files need to be ingested; then use <code>.*\.log</code> as regular expression.</p>
<p><img alt="Screenshot from 2015-09-24 19:36:18.png" src="../images/dtingest/image02.png" /></p>
<p>Where,
-   <code>.\*</code> indicates any character zero or more times
-   <code>\\.</code> indicates dot escaped with backslash '\'
-   <code>log</code> indicates desired extension which is 'log'</p>
<p>Therefore, dtingest ingests only <code>.log</code> files from the source directories.</p>
</li>
<li>
<p>Under 'Runs' field, select 'Single run' if you want application
    to shutdown after ingesting files currently present in the directory.</p>
<p>Select 'Polling' if you expect application to periodically poll the
directory/file for changes. File change detection is based on timestamp. Entire file will be ingested again in case
of any change.</p>
<p>If 'Polling' mode is selected; then 'Polling interval' should be specified.
This is the time interval between sub-sequent scans for detecting
new/modified files.</p>
<p><img alt="Screenshot from 2015-09-24 20:03:57.png" src="../images/dtingest/image17.png" /></p>
</li>
</ol>
<h3 id="configuring-ftp-input">Configuring FTP input</h3>
<p>This section gives details about how to ingest files/directories from FTP using dtIngest.  </p>
<ol>
<li>
<p>Select  FTP as input type
    <img alt="FTPInput.png" src="../images/dtingest/image19.png" /></p>
</li>
<li>
<p>After selecting the FTP as input type, snapshot of UI as below:     <img alt="FTP1.png" src="../images/dtingest/image15.png" /></p>
</li>
<li>
<p>The format for FTP URL input is as follows:  <code>ftp://username:password@host:port/path</code>
    where,</p>
<ul>
<li><code>ftp</code> :  protocol name</li>
<li><code>username</code> :  username for ftp server</li>
<li><code>password</code> : password</li>
<li><code>host</code> : FTP host</li>
<li><code>port</code> : port number</li>
<li><code>path</code> : path to either file / directory</li>
</ul>
<p><img alt="FTP2.png" src="../images/dtingest/image05.png" /></p>
<p>To copy multiple files/directories, see below: 
<img alt="ftp2.png" src="../images/dtingest/image03.png" /></p>
<p>To copy multiple directories, see below:
<img alt="ftp3.png" src="../images/dtingest/image24.png" /></p>
</li>
</ol>
<h3 id="configuring-amazon-s3-input">Configuring Amazon S3 input</h3>
<p>For details on Amazon Simple Storage Service (S3), please go to <a href="https://aws.amazon.com/documentation/s3/">Amazon S3
Documentation</a>. This section gives details about how to
ingest files/directories from S3 using dtIngest.  </p>
<ol>
<li>
<p>Select  S3 as input type
<img alt="S3Input.png" src="../images/dtingest/image30.png" /></p>
</li>
<li>
<p>After selecting the S3 as source type then UI looks like as below:
<img alt="S3_1.png" src="../images/dtingest/image16.png" /></p>
</li>
<li>
<p>Configure S3 input url.</p>
<p>Input url for S3 needs to be provided in following format,<br />
<code>s3n://ukey:upass@bucketName/path</code></p>
<p>where,
- <code>s3n</code>:  protocol name
- <code>ukey</code>: access key
- <code>upass</code>: secret access key
- <code>bucketName</code> : bucketName
- <code>path</code> : path to either file / directory</p>
</li>
</ol>
<p><img alt="S3Input1.png" src="../images/dtingest/image41.png" />
  If you want to copy multiple directories, then click on (+) button and
specify the url’s, UI would be as below:
  <img alt="s3_2.png" src="../images/dtingest/image48.png" /></p>
<h3 id="configuring-kafka-input">Configuring Kafka input</h3>
<p>For more details on Kafka, please refer to <a href="http://kafka.apache.org/documentation.html">Apache Kafka
Documentation</a>.</p>
<p>This section gives details about how to ingest messages from Kafka using dtIngest.</p>
<ol>
<li>
<p>Select Kafka as input type
    <img alt="kafkaInput1.png" src="../images/dtingest/image46.png" /></p>
</li>
<li>
<p>After selecting Kafka as input type then UI looks like as below:
    <img alt="Kafka1.png" src="../images/dtingest/image23.png" /></p>
</li>
<li>
<p>Configure topic name and Zookeeper quorum.
    Zookeeper quorum  is a string in the form of
    <code>hostname1:port1,hostname2:port2,hostname3:port3</code></p>
<p>where,</p>
<ul>
<li><code>hostname1,hostname2,hostname3</code> are hosts</li>
<li><code>port1,port2,port3</code> are ports of zookeeper server</li>
</ul>
<p>e.g. localhost:2181,localhost:2182
<img alt="Kafka.png" src="../images/dtingest/image44.png" /></p>
</li>
<li>
<p>Select the offset type (default is “Latest”). If
    you want to consume messages from beginning of Kafka queue, then
    select “Earliest” offset option.</p>
</li>
<li>
<p>If the topic name is same across the Kafka clusters and want to
    ingest data from these clusters, then configure the Zookeeper quorum
    as follows:</p>
<p><code>c1::hs1:p1,hs2:p2,hs3:p3;c2::hs4:p4,hs5:p5,c3::hs6:p6</code></p>
<p>where,
- <code>c1,c2,c3</code> indicates the cluster names,
- <code>hs1,hs2,hs3,hs4,hs5,hs6</code> are zookeeper host names
- <code>p1,p2,p3,p4,p5,p6</code> are corresponding ports.</p>
<p>For example, ClusterA and ClusterB are 2 Kafka clusters as below, then
Zookeeper quorum would be as <code>ClusterA::node3.example.com:2181,node4.example.com:2181;ClusterB::node8.example.com:2181</code></p>
<p><img alt="KafkaCluster.png" src="../images/dtingest/image04.png" /></p>
</li>
</ol>
<h3 id="configuring-jms-input">Configuring JMS input</h3>
<p>This section gives details about how to ingest messages from
JMS using dtIngest.  </p>
<ol>
<li>
<p>Select JMS as input type.
    <img alt="JMSInput.png" src="../images/dtingest/image18.png" /></p>
</li>
<li>
<p>After selecting the JMS as source type then UI looks like as below:
    <img alt="jms1.png" src="../images/dtingest/image25.png" /></p>
</li>
<li>
<p>Configure Broker URL and topic name as tcp://hostName:port
    <img alt="JMS2.png" src="../images/dtingest/image38.png" /></p>
</li>
</ol>
<h2 id="configuring-output-destination">Configuring Output Destination</h2>
<h3 id="configuring-hdfs-output">Configuring HDFS output</h3>
<ol>
<li>
<p>For 'Output Location' field, select 'HDFS' option from the
    drop-down.</p>
<p><img alt="Screenshot from 2015-09-24 20:08:49.png" src="../images/dtingest/image08.png" /></p>
</li>
<li>
<p>Under 'Target directory' specify complete HDFS path URL of the destination directory. For example,   <code>hdfs://namenode1.cluster.company.org:8020/user/username/path/to/destination/directory</code></p>
<p><img alt="Screenshot from 2015-09-24 20:51:55.png" src="../images/dtingest/image47.png" /></p>
</li>
</ol>
<p>Where,
    - <code>hdfs://</code> indicates HDFS protocol
    - <code>namenode1.cluster.company.org</code> indicates fully qualified domain name for
    the namenode of destination HDFS.
    - <code>:8020</code> indicates port number for HDFS namenode service
    - <code>/user/username/path/to/destination/directory</code> indicates full path
    for destination directory.</p>
<ol>
<li>
<p>Under 'Recursive copy' option, select 'Yes' if you wish to copy
    entire directory structure under source directory to the
    destination. Select 'No' if you want non-recursive copy.</p>
</li>
<li>
<p>Under 'Overwrite conflicting files' option, select 'Yes' if you
    wish to overwrite the file at the destination if file with the same
    name is discovered under input source.</p>
</li>
</ol>
<h4 id="compact-files">Compact files</h4>
<p>Use 'Compact files' feature if you want to partition data into fix size. This
can be used to combine large number of small files into partitions of
manageable size. Vice versa, you can break down a very
large file into partitions of manageable size.</p>
<p><img alt="Screenshot from 2015-10-16 11:04:39.png" src="../images/dtingest/image28.png" /></p>
<ol>
<li>
<p>Select 'yes' for radio button under 'Compact files' option. This
    will display additional options for compaction. If you do not
    want to compact files but copy them as they are; then select 'no'
    for 'Compact files' option. If you select 'no' ; additional
    options for compaction will be hidden.</p>
</li>
<li>
<p>Select delimiter to be used for separating contents of the files.
    This will be useful if you decide to use some custom logic for
    parsing partition files. Default value for 'delimiter' option is
    'none'. You can use new line or any other custom delimiter based
    on your requirement. Note that, special characters in the custom
    delimiter should be escaped with <code>\</code>. For example, tab character
    <code>\t</code> should be specified as <code>\\t</code>.</p>
</li>
<li>
<p>Specify the size for each partition under 'Max compacted file
    size'. You can specify partition size in bytes, MB, GB. Data will
    spill over to the next partition once this size is reached.</p>
</li>
</ol>
<p>Note that, partition will be of exact sizes in case of continuous
incoming data. If there is no incoming data for consecutive 600 windows
then that partition will be committed to the HDFS. In this case, new
incoming data will be spilled to the next partition.</p>
<h3 id="configuring-nfs-output">Configuring NFS output</h3>
<ol>
<li>
<p>For ‘Output Location’ field; select ‘File/NFS’ option from the
    drop-down  </p>
<p><img alt="" src="../images/dtingest/image00.png" /></p>
</li>
<li>
<p>Under ‘Target directory’ specify complete NFS path URL of the destination directory.<br />
    For example,  if the NFS mount is located at '/disk5/nfsmount' and
    'path/to/data/directory' is the directory under this mount which
    needs to be ingested; then complete URL in this case will be
    <code>file:///disk5/nfsmount/path/to/data/directory</code></p>
<p>Where,</p>
<ul>
<li><code>file://</code> indicates that it is some file system mounted on the node.</li>
<li><code>/disk5/nfsmount/</code> indicates the mount point.
Note that, this has to be uniform across all the nodes in cluster.</li>
<li><code>path/to/data/directory</code> is the directory to be ingested</li>
</ul>
<p><img alt="" src="../images/dtingest/image11.png" /></p>
<p>Note that, for the above example, there should be <code>///</code> (triple slash)
after <code>file:</code>.</p>
</li>
</ol>
<h3 id="configuring-ftp-output">Configuring FTP output</h3>
<ol>
<li>
<p>Select FTP as output type.
    <img alt="FTPOutput1.png" src="../images/dtingest/image34.png" /></p>
</li>
<li>
<p>After selecting FTP as output type then UI looks like as below:   <img alt="FTPOUtput3.png" src="../images/dtingest/image42.png" /></p>
</li>
<li>
<p>Specify the destination URL below the “Output directory” label.
    The FTP Output URL is as follows: <code>ftp://username:password@host:port/path</code></p>
<p>Where,
- <code>ftp</code> :  protocol name
- <code>username</code> : username for ftp server
- <code>password</code> : password
- <code>host</code> : FTP host
- <code>port</code> : port number
- <code>path</code> : Directory path to ingested</p>
<p><img alt="HFTP2.png" src="../images/dtingest/image01.png" /></p>
</li>
</ol>
<h3 id="configuring-amazon-s3-output">Configuring Amazon S3 output</h3>
<ol>
<li>
<p>Select S3 as output type.
    <img alt="S3Output1.png" src="../images/dtingest/image09.png" /></p>
</li>
<li>
<p>After selecting S3 as output then UI looks like as below:
    <img alt="H2S3_12.png" src="../images/dtingest/image36.png" /></p>
</li>
<li>
<p>Specify URL destination below the 'Output directory' label.
The S3 output URL is as follows: <code>s3n://ukey:upass@bucketName/path</code>
    Where,</p>
<ul>
<li><code>s3n</code> : protocol name</li>
<li><code>ukey</code> : access key</li>
<li><code>upass</code> : secret access key</li>
<li><code>bucketName</code> :  bucketName</li>
<li><code>path</code> : Directory path</li>
</ul>
</li>
</ol>
<h3 id="configuring-kafka-output">Configuring Kafka output</h3>
<ol>
<li>
<p>Select Kafka as output type.
    <img alt="KafkaOutput1.png" src="../images/dtingest/image35.png" /></p>
</li>
<li>
<p>After selecting Kafka as output then UI looks like as below:
    <img alt="K2K2.png" src="../images/dtingest/image22.png" /></p>
</li>
<li>
<p>Configure broker list and topic name.</p>
</li>
</ol>
<h3 id="configuring-jms-output">Configuring JMS output</h3>
<ol>
<li>
<p>Select JMS as output type.
<img alt="JMSOutput1.png" src="../images/dtingest/image20.png" /></p>
</li>
<li>
<p>After selecting JMS as output type then UI looks like as below:
<img alt="K2J1.png" src="../images/dtingest/image21.png" /></p>
</li>
<li>
<p>Configure Broker URL and topic name as tcp://host:port
<img alt="K2J2.png" src="../images/dtingest/image40.png" /></p>
</li>
</ol>
<h2 id="configuring-processing-steps">Configuring Processing Steps</h2>
<h3 id="configuring-compression">Configuring compression</h3>
<p>Select compression type on configuration page       <br />
<img alt="" src="../images/dtingest/image07.png" /></p>
<ol>
<li>Select LZO radio button to apply LZO compression<br />
<img alt="" src="../images/dtingest/image43.png" /></li>
</ol>
<p>Lzo compression is not directly supported. To use lzo compression provide
  plugin to ingestion app which provides lzo implementation and extends from java FilterOutputStream class. Copy plugin to \~/.dt/plugins folder
  (i.e. HOME_DIR/.dt/plugins) of the user who launches ingestion app.
  We do ship default lzo plugin, and is available to download on maven repository at
https://oss.sonatype.org/content/repositories/releases/com/datatorrent/dtIngest-lzo/1.0.0/</p>
<ol>
<li>Select GZIP radio button to apply GZIP compression
<img alt="" src="../images/dtingest/image12.png" /></li>
</ol>
<h3 id="configuring-encryption">Configuring encryption</h3>
<p>Select encryption type on configuration page.
<img alt="" src="../images/dtingest/image27.png" /></p>
<ol>
<li>Apply AES encryption:</li>
<li>
<p>Select AES radio button to apply AES encryption</p>
</li>
<li>
<p>Provide AES symmetric encryption key in “AES key” text box<br />
     Note: AES symmetric key should be of size 128, 192 or 256 bits.
<img alt="" src="../images/dtingest/image06.png" /></p>
</li>
<li>
<p>Apply PKI encryption:  </p>
<ol>
<li>Select PKI encryption button to apply PKI encryption  </li>
<li>Provide Asymmetric public key to be used for PKI encryption  </li>
</ol>
<p><img alt="" src="../images/dtingest/image29.png" /></p>
</li>
</ol>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../rts/" class="btn btn-neutral float-right" title="RTS">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../app_data_tracker/" class="btn btn-neutral" title="App Data Tracker"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../app_data_tracker/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../rts/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
